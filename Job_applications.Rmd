---
title: "Job_applications"
authors: "Sajan Kumar Kar, Sai Pavan Mekala, Neelima Puthanveetil, Sandhya Karki"
date: "2023-10-15"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Team Global project on Job Applicants Data
## 1. Import Libraries


```{r Libraries}
# uncomment and run the below line to install the required packages
#install.packages(c("gganimate", "png", "gifski"))
library(ggplot2)
library(tidyr)
library(dplyr)
library(ezids)
library(gganimate)
library(png)
library(gifski)

```

## 2. Import Data

```{r Import_data}
df = data.frame(read.csv('stackoverflow_full.csv', header = TRUE))
xkabledplyhead(df, title = "Job Applicants Data")
```
```{r Structure}
#structure of a data frame 
str(df) 
```

The dataframe has 73462 records. We have `index`, `employemnt`, `yearscode`, `yearscodepro` and `previoussalary` as integer type and the rest are of character types. Going ahead we would need to convert some of them to factors.

## 3. Data preprocessing & Cleaning

Let's first check for missing values and duplicate values if any.

```{r missing values}
# Check the missing values and count them in each column
print(colSums(is.na(df)))
```


```{r duplicates}
# Check duplicates
length(unique(df$Index))
```

We notice that there are no missing values and duplicates in the data. So, we have all the observations to work with.

Now that we know this, let us do some cleaning and feature engineering. First we'll extract the numeric columns.

```{r Numeric columns}
# Extract the numeric columns
head(subset(df, select = c(names(df)[sapply(df, is.numeric)])))
```


```{r numeric feature cleaning}
df_clean <- subset(df, select = -c(Index))
df_clean$Employment = as.character(df_clean$Employment)
df_clean$Employment[df_clean$Employment == "1"] <- "currently_employed"
df_clean$Employment[df_clean$Employment=="0"] <- "not_currently_employed"
df_clean$Employment = factor(df_clean$Employment)
df_clean$Employed = as.character(df_clean$Employed)
df_clean$Employed[df_clean$Employed == "1"] <- "hired"
df_clean$Employed[df_clean$Employed == "0"] <- "not_hired"
df_clean$Employed = factor(df_clean$Employed)
str(df_clean)
```

Now let's take a look at the character columns.

```{r char columns}
# Extract the character columns
head(subset(df_clean, select = c(names(df)[sapply(df, is.character)])))

```

```{r char feature cleaning}
df_clean$Age = factor(df_clean$Age)
df_clean$Accessibility = factor(df_clean$Accessibility)
df_clean$EdLevel = factor(df_clean$EdLevel, ordered = T, 
                          levels = c("Other", "NoHigherEd", "Undergraduate", "Master", "PhD"))
df_clean$Gender = factor(df_clean$Gender)
df_clean$MentalHealth = factor(df_clean$MentalHealth)
df_clean$MainBranch = factor(df_clean$MainBranch)
str(df_clean)
```


Let's check the number of different countries we have.

```{r country}
length(unique(df_clean$Country))

```

There are 172 different countries. (Leaving this as it is for the time being)

Let's see if there is data where their professional coding experience is more than their coding experience. If there is such data, we have to remove it because that's practically faulty data.

```{r remove faulty data}

nrow(subset(df_clean, subset = df_clean$YearsCode<df_clean$YearsCodePro))
# We observe 588 such records
df_clean = subset(df_clean, subset = df_clean$YearsCode>df_clean$YearsCodePro)

```


Let's take a look at some plots and distribution in order to deal with outliers.

```{r outlier detection}
# Create a list of the columns that we use in combined boxplot
columns_to_plot <- c("YearsCode", "YearsCodePro", "PreviousSalary", "ComputerSkills")

# Set up the plotting area to display all boxplots together
par(mfrow = c(2, length(columns_to_plot)))

# Display the boxplots
for (i in 1:length(columns_to_plot)) {
  boxplot(df_clean[[columns_to_plot[i]]], main = columns_to_plot[i],col = "lightblue")
}
for (i in 1:length(columns_to_plot)) {
  hist(df_clean[[columns_to_plot[i]]], main = columns_to_plot[i], xlab = element_blank(), col = "lightblue")
}
# plotting area layout
par(mfrow = c(2, 1))

```

```{r quantiles}
o_code= quantile(df_clean$YearsCode, probs = 0.75, na.rm = FALSE) + 
  (1.5 * IQR(df_clean$YearsCode))
o_procode = quantile(df_clean$YearsCodePro, probs = 0.75, na.rm = FALSE) + 
  (1.5 * IQR(df_clean$YearsCodePro))
o_presal = quantile(df_clean$PreviousSalary, probs = 0.75, na.rm = FALSE) + 
  (1.5 * IQR(df_clean$PreviousSalary))
o_cskill = quantile(df_clean$ComputerSkills, probs = 0.75, na.rm = FALSE) + 
  (1.5 * IQR(df_clean$ComputerSkills))

print(paste(o_code, o_procode, o_presal, o_cskill))
```

```{r outlier removal}
df_clean = subset(df_clean, subset = df_clean$YearsCode < 40)
df_clean = subset(df_clean, subset = df_clean$YearsCodePro < 40)
df_clean = subset(df_clean, subset = df_clean$ComputerSkills < 35)
```


Lets take a look at the final data now:

```{r final data}
df_final <- df_clean
xkabledplyhead(df_final, title = "Final Data")

```

```{r Final Data Basic Info}

# Getting the number of categorical and numerical columns
cat_cols <- colnames(subset(df_final, select = c(names(df_final)[(sapply(df_final, is.factor)) | 
                                                       (sapply(df_final, is.ordered)) | 
                                                       (sapply(df_final, is.character))])))

num_cols <- colnames(subset(df_final, select = c(names(df_final)[sapply(df_final, is.integer)])))

# Displaying the information
cat("Basic summary and Raw Counts for the Dataset:\n")
cat("Rows:", dim(df_final)[1], "\n")
cat("Columns:", dim(df_final)[2], "\n")
cat("Numerical columns:", num_cols, "\n")
cat("Categorical Columns:", cat_cols, "\n")

```

## 4. EDA

Let's first try to get a good picture of the data which will act as the 1st step to answer the questions that we proposed.


```{r plot- Ed by Gender}

ggplot(data = subset(df_final, subset = Employed=='hired'), aes(EdLevel, after_stat(count))) + 
  geom_bar(aes(fill = Gender), position = 'dodge', alpha = 0.5) +
  labs(title = "Education Level by gender for employed workers", x="Education Level", y="Count")

```


```{r plot- Ed by Emp}
ggplot(data = df_final, aes(EdLevel)) + 
  geom_bar(aes(fill = Employment), position = 'dodge', alpha = 0.5) +
  labs(title = "Education Level by Employment", x="Education Level", y="Count")

```


```{r plot- MainBranch by Age}
ggplot(data = df_final, aes(MainBranch)) + 
  geom_bar(aes(fill = Age), position = 'dodge', alpha = 0.5) +
  labs(title = "MainBranch by Age", x="MainBranch", y="Count")

```


```{r plot- PrevSal by MentalHealth(1)}
ggplot(data = df_final, aes(x = PreviousSalary, fill = MentalHealth)) +
  geom_density(alpha = 0.5) +
  labs(title = "Density plot of Previous Salary by Mental Health", x="Previous Salary", y= 'Density')

```


```{r plot- PrevSal by MentalHealth(2)}

ggplot(data = df_final, aes(x = MentalHealth, y = PreviousSalary)) +
  geom_jitter(alpha = 0.5, col = 'navy') +
  labs(title = "Previous Salary by Mental Health", x = 'Mental Health', y="Previous Salary")

```

```{r plot- PrevSal by MentalHealth(3)}
plotdata <- df_final %>%
  group_by(MentalHealth) %>%
  summarize(mean_prevsalary = mean(PreviousSalary))

ggplot(data = plotdata, aes(x = MentalHealth, y = mean_prevsalary)) +
  geom_bar(stat = 'identity', alpha = 0.5, aes(fill = MentalHealth)) +
  labs(title = "Mean Previous Salary by Mental Health", x = 'Mental Health', y="Previous Salary")

```
We notice that the mean previous salary of applicants having mental health issues is higher.


Let's try digging a bit deeper into the data to get additional insights.
Let's try to extract the most used skill-
```{r skills extraction}

df_final %>%
separate_rows(HaveWorkedWith, sep = ";") %>% 
group_by(HaveWorkedWith) %>%
summarise(Count = n()) %>%
arrange(desc(Count)) -> skills_df
head(skills_df, 10)
```

We see that Javascript, Docker and HTML/CSS are the skills known by majority of the applicants. Let's visualize it to have a better look.

```{r plot- Top 10 skills known}

plot <- ggplot(data = head(skills_df, 10), aes(x = reorder(HaveWorkedWith, Count), y = Count)) + 
  geom_bar(stat = 'identity', aes(fill = HaveWorkedWith), alpha = 0.6) + 
  coord_flip() + 
  theme(axis.text.x = element_blank(),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_line(size = 0.1, color = "grey"),
        panel.grid.minor.x = element_line(size = 0.1, color = "grey"),
        plot.background = element_blank()) + 
  geom_text(aes(y = Count, label = Count)) +
  labs(title = "Skills used by number of applicants", 
       x = "Skill", y = "No. of applicants possessing the skill")

anim <- plot + 
    transition_states(HaveWorkedWith, transition_length = 4, wrap = FALSE) + 
  shadow_mark() + 
  enter_grow() +
  enter_fade() + 
  ease_aes('sine-in')
  
animate(anim)
#anim_save("Skills.gif", anim)
```
Because we have over 65,000 data points, we can use statistical methods that apply to data satisfying normality conditions (because of the central limit theorem).


## 5. Hypothesis Testing

### Test 1: Is there a significant difference between employed males and non-males in their respective education levels?

We first want to check whether there is a difference in the number of males vs non-males employed at every level of education.

Because we have over 65,000 data points, we may use statistical methods that apply to data satisfying normality conditions (because of the central limit theorem).

Hence, we use a series of two sample z tests to conduct our first set hypothesis tests.

The assumptions we need to satisfy are:
- Large sample size\
- Data are collected as a simple random sample (so that observations are independent from one another)

We first want to look at the individuals with a bachelor's degree.
$H_0:$ There is no difference in the number of undergraduate males who are employed when compared to nonmales
$H_a:$ There is a significant difference in the number of undergraduate males who are employed when compared to nonmales
```{r, two sample z test for proportions: undergraduate}
# We first subset into the different education levels, here undergraduate
undergrad <- subset(df_clean, df_clean$EdLevel == "Undergraduate")


# For the two sample z test, we need our two samples, males and nonmales
undergrad_male <- subset(undergrad, undergrad$Gender == "Man") # Sample 1, males

undergrad_male_employed <- subset(undergrad_male, undergrad_male$Employment == "currently_employed")

undergrad_nonmales <- subset(undergrad, undergrad$Gender != "Man") # Sample 2, females and nonbinary

undergrad_nonmales_employed <- (subset(undergrad_nonmales, undergrad_nonmales$Employment == "currently_employed"))


undergrad_employed_ztest <- prop.test(c(nrow(undergrad_male_employed), nrow(undergrad_nonmales_employed)), c(nrow(undergrad_male),nrow(undergrad_nonmales)))
undergrad_employed_ztest
```
The proportion of undergraduate males who are employed is: `r nrow(undergrad_male_employed)`/`r nrow(undergrad_male)`\
The proportion of undergraduate nonmales who are employed is: `r nrow(undergrad_nonmales_employed)`/`r nrow(undergrad_nonmales)`\
Our two sample z test statistic is: `r undergrad_employed_ztest$statistic` which has an associated p-value of `r undergrad_employed_ztest$p.value`.\
At and alpha-level of .05 we fail to reject the null hypothesis and conclude that there is not a significant difference in the number of males vs nonmales who have a bachelor's degree and are employed.

We now look at individuals with a masters.
$H_0:$ There is no difference in the number of males with a master's degree who are employed when compared to nonmales
$H_a:$ There is a significant difference in the number of males with a master's degree who are employed when compared to nonmales

```{r, two sample z test for proportions: masters}
# We first subset into the different education levels, here masters
masters <- subset(df_clean, df_clean$EdLevel == "Master")


# For the two sample z test, we need our two samples, males and nonmales
masters_male <- subset(masters, masters$Gender == "Man") # Sample 1, males

masters_male_employed <- subset(masters_male, masters_male$Employment == "currently_employed")


masters_nonmales <- subset(masters, undergrad$Gender != "Man") # Sample 2, females and nonbinary

masters_nonmales_employed <- (subset(masters_nonmales, masters_nonmales$Employment == "currently_employed"))


masters_employed_ztest <- prop.test(c(nrow(masters_male_employed), nrow(masters_nonmales_employed)), c(nrow(masters_male),nrow(masters_nonmales)))
masters_employed_ztest

```
The proportion of males with a master's who are employed is: `r nrow(masters_male_employed)`/`r nrow(masters_male)`\
The proportion of nonmales with a master's who are employed is: `r nrow(masters_nonmales_employed)`/`r nrow(masters_nonmales)`\
Our two sample z test statistic is: `r masters_employed_ztest$statistic` which has an associated p-value of `r masters_employed_ztest$p.value`.\
At and alpha-level of .05 we reject the null hypothesis and conclude that there is a significant difference in the number of males vs nonmales who have a master's degree and are employed.

Finally, we examine individuals who have a doctorate degree.
$H_0:$ There is no difference in the number of males with a PhD who are employed when compared to nonmales
$H_a:$ There is a significant difference in the number of males with a PhDwho are employed when compared to nonmales
```{r, two sample z test for proportions: Phd}
# We first subset into the different education levels, here PhD
phd <- subset(df_clean, df_clean$EdLevel == "PhD")


# For the two sample z test, we need our two samples, males and nonmales
phd_male <- subset(phd, phd$Gender == "Man") # Sample 1, males

phd_male_employed <- subset(phd_male, phd_male$Employment == "currently_employed")

phd_nonmales <- subset(phd, phd$Gender != "Man") # Sample 2, females and nonbinary

phd_nonmales_employed <- (subset(phd_nonmales, phd_nonmales$Employment == "currently_employed"))


phd_employed_ztest <- prop.test(c(nrow(phd_male_employed), nrow(phd_nonmales_employed)), c(nrow(phd_male),nrow(phd_nonmales)))
phd_employed_ztest
```
The proportion of males with a master's who are employed is: `r nrow(phd_male_employed)`/`r nrow(phd_male)`\
The proportion of nonmales with a master's who are employed is: `r nrow(phd_nonmales_employed)`/`r nrow(phd_nonmales)`\
Our two sample z test statistic is: `r phd_employed_ztest$statistic` which has an associated p-value of `r phd_employed_ztest$p.value`.\
At and alpha-level of .05 we fail to reject the null hypothesis and conclude that there is not a significant difference in the number of males vs nonmales who have a doctorate degree and are employed.

In real-world scenarios, these results might suggest that, in certain employment contexts, master's education appears to be a distinguishing factor between males and non-males. This could reflect societal or industry biases, or possibly differing educational or career choices among genders. Companies keen on diversity might want to address such disparities in their recruitment and mentorship programs, ensuring opportunities aren't skewed by gender-based educational trends.

### Test 2: Does education level significantly impact employment in the technical field?
Since we the number of known computer skills is continuous and we have more than two categories for level of education, we would like to conduct an ANOVA test to answer this question.

The assumptions we need to satisfy are:
- All 5 groups are normally distributed\
- Homogeneity of variances\
- Error terms are independent of each other

Let's first visualize the question we are trying to answer by examining the boxplots for distribution of computer skills at all education levels.
```{r, ANOVA boxplots}
loadPkg("ggplot2")
ggplot(df_clean, aes(x=EdLevel, y=ComputerSkills)) + 
  geom_boxplot( colour=c("#ff0000","#FFFF00", "#11cc11","#0000ff","#ff00ff"), alpha = .5, outlier.shape=8, outlier.size=4) +
  labs(x="Education Level", y = "Number of Computer Skills")
```

There seem to be at least some differences, and we solidify this by conducting our hypothesis test using ANOVA.

$H_0:$: There is no significant difference in the average number of computer skills acquired when comparing all individuals at every level of education.
$H_a:$ At least one education level group differs from the others in the average number of computer skills known.

```{r, ANOVA test}
anovaRes = aov(ComputerSkills ~ EdLevel, data=df_clean)
anovaSummary = summary(anovaRes)
anovaSummary

# Extracting mean computer skills for each education level
mean_skills_Other = mean(subset(df_clean, EdLevel == "Other")$ComputerSkills)
mean_skills_NoHigherEd = mean(subset(df_clean, EdLevel == "NoHigherEd")$ComputerSkills)
mean_skills_Undergraduate = mean(subset(df_clean, EdLevel == "Undergraduate")$ComputerSkills)
mean_skills_Master = mean(subset(df_clean, EdLevel == "Master")$ComputerSkills)
mean_skills_PhD = mean(subset(df_clean, EdLevel == "PhD")$ComputerSkills)
```
The average number of computer skills for\
Other: `r mean_skills_Other`\
No Higher Ed: `r mean_skills_NoHigherEd`\
Undergraduate: `r mean_skills_Undergraduate`\
Master's: `r mean_skills_Master`\
PhD: `r mean_skills_PhD`\
Our ANOVA F test statistic is 281.8 with p-value <2e-16. At an alpha-level of .05, we reject the null hypothesis. We conclude that there is at least one education level for which the average number of computer skills is different from the other groups.

Since we have a highly significant p-value based on our ANOVA test above, we want to conduct a Post Hoc analysis of the test using the standard method, Tukey's HSD test.
```{r, Post Hoc Tukeys Test}
tukeyRes <- TukeyHSD(anovaRes)
tukeyRes
```

Since all p-values for every pairwise comparison was less than 0.05, we conclude that the average number of computer skills for every education level was significantly different from every other level of education.

[real world conclusion; we could look at specific averages to determine which levels of education provide less or more computer skills i.e. quality vs quantity]

In real-world terms, this suggests that as one progresses through higher levels of education, from no higher education to a PhD, there is a substantial increase in computer skills. For employers in the technical field, this could mean that candidates with advanced degrees might bring a higher level of expertise and proficiency in computer-related tasks. However, it's also essential to consider the quality versus quantity aspect: while a higher degree might indicate more extensive knowledge, it does not necessarily guarantee the quality or applicability of that knowledge in specific job roles.

### Test 3: Is age a significant factor in determining whether an individual is a professional developer or not?
Now, since age is a continuous variable and the classification for professional development a categorical one, we would like to use a Chi square test of independence to determine whether the two variables are associated.

The assumptions we need to satisfy are:
- The data were drawn as a simple random sample\
- All expected counts are greater than 5

$H_0:$ Whether an individual is a professional developer or not is independent of their age.
$H_a:$ Age and status of being a professional developer are associated with each other.
```{r, Chi square}
# We need four categories: <35, NotDev; >35, NotDev; <35 Dev; >35 Dev
notDev_under35 <- subset(df_clean, df_clean$Age == "<35" & df_clean$MainBranch == "NotDev")
notDev_over35 <- subset(df_clean, df_clean$Age == ">35" & df_clean$MainBranch == "NotDev")
dev_under35 <- subset(df_clean, df_clean$Age == "<35" & df_clean$MainBranch == "Dev")
dev_over35 <- subset(df_clean, df_clean$Age == ">35" & df_clean$MainBranch == "Dev")
```

The contingency table that we perform our chi square test on is the following:
```{r, Chi square table}
chisq_matrix <- matrix(c(nrow(dev_over35),nrow(dev_under35),nrow(notDev_over35),nrow(notDev_under35)), nrow = 2, ncol = 2)

# Now we conduct a chi square test of independence
chitest = chisq.test(chisq_matrix)
chitest
```
Our chi square test statistic is `r chitest$statistic` with p-value `r chitest$p.value`. At an alpha-level of .05 we reject the null hypothesis. We conclude that age and being a professional developer are associated.

This data might imply that certain age groups are more inclined or better positioned to pursue developer careers. For educational institutions, this insight can guide curriculum planning, targeting age groups that are more likely to transition into professional development.

### Test 4: Does mental health influence previous salary?
To answer our final question, we conduct a two sample t test to compare the mean salary between those with and without mental health issues. (We use a t test as opposed to its normal counterpart, a z test, even though we have a large sample, size since the population variance is unknown.)

The assumptions we need to satisfy are:
- The observations are independent of one another\
- The data in each group were take from a simple random sample\
- The data are relatively normally distributed
- The data is continuous in nature\
- Homogeneity of variances

$H_0:$ Whether an individual is a professional developer or not is independent of their age.
$H_a:$ Age and status of being a professional developer are associated with each other.
```{r, two sample t-test for means}
# Subset the PreviousSalary for individuals with 'Yes' and 'No' in the MentalHealth column
salary_yes <- df_clean$PreviousSalary[df_clean$MentalHealth == "Yes"]
salary_no <- df_clean$PreviousSalary[df_clean$MentalHealth == "No"]

# Checking the mean of both groups just to get an idea
format(mean(salary_yes, na.rm = TRUE), digits=5)
format(mean(salary_no, na.rm = TRUE), digits=5)

# Now we conduct a two-sample t-test on PreviousSalary between the two groups
ttest_2sample_salary_yes_no <- t.test(salary_yes, salary_no)
ttest_2sample_salary_yes_no

```
The average salary for those who responded\ 
'yes' to having mental health issues: $72,709.47\
'no' to having mental health issues: $64,652.15\
Our t test statistic is `r ttest_2sample_salary_yes_no$statistic` with p-value `r ttest_2sample_salary_yes_no$p.value`. At an alpha-level of .05 we reject the null hypothesis. We conclude that the mean salary of those with mental health issues is significantly different (in this case, higher) than those without.

This shows that those acknowledging mental health issues earned between $7,141 to $8,973 more than those who didn't. This suggests that a higher salary often carries added responsibilities, leading to stress and potential mental health challenges. Companies and HR teams can use this insight to monitor employee well-being. Job seekers should also be aware that higher salaries might come with increased mental health considerations, aiding them in making informed decisions.

