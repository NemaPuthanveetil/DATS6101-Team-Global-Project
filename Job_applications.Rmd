---
title: "Job_applications"
authors: "Sajan Kumar Kar, Sai Pavan Mekala, Neelima Puthanveetil, Sandhya Karki"
date: "2023-10-15"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Import Libraries
Team Global project on Job Applications Data

```{r Libraries}
# uncomment and run the below line to install the required packages
#install.packages(c("gganimate", "png", "gifski"))
library(ggplot2)
library(tidyr)
library(dplyr)
library(ezids)
library(gganimate)
library(png)
library(gifski)
library(gridExtra)
library(maps)
```

## 2. Import Data

```{r Import_data}
df = data.frame(read.csv('stackoverflow_full.csv', header = TRUE))
xkabledplyhead(df)
```
```{r Structure}
#structure of a data frame 
str(df) 
```

The dataframe has 73462 records. We have index, employemnt, yearscode, yearscodepro and previoussalary as integer type and the rest are of character types. Going ahead we would need to convert some of them to factors.

## 3. Data preprocessing & Cleaning

Let's first check for missing values and duplicate values if any.

```{r missing values}
# Check the missing values and count them in each column
print(colSums(is.na(df)))
```

Here we checks the number of unique values in the "Index" column of the dataframe "df" to identify duplicates.


```{r duplicates}
# Check duplicates
length(unique(df$Index))
```

In this we  provided basic dataset statistics, including row and column counts, the number of discrete and continuous columns, and memory allocation information.

```{r Basic Statistics}

# Getting the number of rows and columns
num_rows <- dim(df)[1]
num_columns <- dim(df)[2]

# Getting the number of discrete and continuous columns
discrete_columns <- sum(sapply(df, is.factor))
continuous_columns <- sum(sapply(df, is.numeric))

# Checking for missing values
missing_columns <- sum(colSums(is.na(df)) > 0)
missing_observations <- sum(rowSums(is.na(df)) > 0)

# Getting the number of complete rows
complete_rows <- sum(complete.cases(df))

# Calculating the total number of observations
total_observations <- num_rows * num_columns

# Memory allocation
memory_allocation <- format(object.size(df), units = "Mb")

# Displaying the information
cat("Basic Statistics and Raw Counts for the Dataset:\n")
cat("Rows:", num_rows, "\n")
cat("Columns:", num_columns, "\n")
cat("Discrete columns:", discrete_columns, "\n")
cat("Continuous columns:", continuous_columns, "\n")
cat("All missing columns:", missing_columns, "\n")
cat("Missing observations:", missing_observations, "\n")
cat("Complete Rows:", complete_rows, "\n")
cat("Total observations:", total_observations, "\n")
cat("Memory allocation:", format(memory_allocation, units = "auto"), "\n")

```
In this we  provided basic dataset statistics, including row and column counts, the number of discrete and continuous columns, and memory allocation information.

```{r Structure}


num_rows <- dim(df)[1]
num_columns <- dim(df)[2]

discrete_columns <- sum(sapply(df, is.factor))
continuous_columns <- sum(sapply(df, is.numeric))

missing_columns <- sum(colSums(is.na(df)) > 0)
missing_observations <- sum(rowSums(is.na(df)) > 0)

complete_rows <- sum(complete.cases(df))

total_observations <- num_rows * num_columns

statistics <- data.frame(
  Statistic = c("Rows", "Columns", "Discrete Columns", "Missing Observations", "Total Observations"),
  Count = c(num_rows, num_columns, discrete_columns, missing_observations, total_observations)
)

statistics$Percentage <- (statistics$Count / sum(statistics$Count)) * 100

bar_plot <- ggplot(statistics, aes(x = Statistic, y = Percentage)) +
  geom_bar(stat = "identity", width = 0.7, fill = "skyblue") +
  geom_text(aes(label = paste0(Percentage, "%")), vjust = -0.5, size = 4) +
  labs(title = "Percentage Breakdown of Dataset Statistics",
       x = "Statistic", y = "Percentage") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(bar_plot)

 
```

We notice that there are no missing values and duplicates in the data. So, we have all the observations to work with.

Now that we know this, let us do some cleaning and feature engineering. First we'll extract the numeric columns.

```{r Numeric columns}
# Extract the numeric columns
head(subset(df, select = c(names(df)[sapply(df, is.numeric)])))
```

* The index column will not be required, so we will drop it (We can use the in-built index of a dataframe).
* We will convert employment into factor and change the values for a better sense.
* We will do the same for employed

```{r numeric feature cleaning}
df_clean <- subset(df, select = -c(Index))
df_clean$Employment = as.character(df_clean$Employment)
df_clean$Employment[df_clean$Employment == "1"] <- "currently_employed"
df_clean$Employment[df_clean$Employment=="0"] <- "not_currently_employed"
df_clean$Employment = factor(df_clean$Employment)
df_clean$Employed = as.character(df_clean$Employed)
df_clean$Employed[df_clean$Employed == "1"] <- "hired"
df_clean$Employed[df_clean$Employed == "0"] <- "not_hired"
df_clean$Employed = factor(df_clean$Employed)
str(df_clean)
```

Now let's take a look at the character columns.

```{r char columns}
# Extract the character columns
head(subset(df_clean, select = c(names(df)[sapply(df, is.character)])))

```

* Except Country and Haveworkedwith, the rest are clearly categorical features, so we will convert them to factor data type
* Edlevel is an ordinal feature 


```{r char feature cleaning}
df_clean$Age = factor(df_clean$Age)
df_clean$Accessibility = factor(df_clean$Accessibility)
df_clean$EdLevel = factor(df_clean$EdLevel, ordered = T, 
                          levels = c("Other", "NoHigherEd", "Undergraduate", "Master", "PhD"))
df_clean$Gender = factor(df_clean$Gender)
df_clean$MentalHealth = factor(df_clean$MentalHealth)
df_clean$MainBranch = factor(df_clean$MainBranch)
str(df_clean)
```

*"Other" for now is set to be the lowest level. Ideally it should be excluded from the ranking of the levels. But there are about 10000 observations with "other", hence we cannot drop so many rows*

Let's check the number of different countries we have.

```{r country}
length(unique(df_clean$Country))

```

There are 172 different countries. (Leaving this as it is for the time being)

Let's see if there is data where their professional coding experience is more than their coding experience. If there is such data, we have to remove it because that's practically faulty data.

```{r remove faulty data}

nrow(subset(df_clean, subset = df_clean$YearsCode<df_clean$YearsCodePro))
# We observe 588 such records
df_clean = subset(df_clean, subset = df_clean$YearsCode>df_clean$YearsCodePro)

```


Let's take a look at some plots and distribution in order to deal with outliers.

```{r outlier detection}
# Create a list of the columns that we use in combined boxplot
columns_to_plot <- c("YearsCode", "YearsCodePro", "PreviousSalary", "ComputerSkills")

# Set up the plotting area to display all boxplots together
par(mfrow = c(2, length(columns_to_plot)))

# Display the boxplots
for (i in 1:length(columns_to_plot)) {
  boxplot(df_clean[[columns_to_plot[i]]], main = columns_to_plot[i],col = "lightblue")
}
for (i in 1:length(columns_to_plot)) {
  hist(df_clean[[columns_to_plot[i]]], main = columns_to_plot[i], xlab = element_blank(), col = "lightblue")
}
# plotting area layout
par(mfrow = c(2, 1))

```

So we notice that, all these are right skewed distributions with quite a bit of outliers. All the outliers are on the higher end. Let's check the crictical value for these outliers.

```{r quantiles}
o_code= quantile(df_clean$YearsCode, probs = 0.75, na.rm = FALSE) + 
  (1.5 * IQR(df_clean$YearsCode))
o_procode = quantile(df_clean$YearsCodePro, probs = 0.75, na.rm = FALSE) + 
  (1.5 * IQR(df_clean$YearsCodePro))
o_presal = quantile(df_clean$PreviousSalary, probs = 0.75, na.rm = FALSE) + 
  (1.5 * IQR(df_clean$PreviousSalary))
o_cskill = quantile(df_clean$ComputerSkills, probs = 0.75, na.rm = FALSE) + 
  (1.5 * IQR(df_clean$ComputerSkills))

print(paste(o_code, o_procode, o_presal, o_cskill))
```

So, as per the IQR method, for it to be an outlier we get:

* 39.5 years of coding experience
* 25.5 years of professional coding experience
* 193596 as the previous salary
* 30.5 as the number of computer skills

Someone can have 25.5+ years of professional coding experience. So, it doesn't make sense to remove everything above this value. A good approximation would be 40 years. So we'll consider anyone who has above 40 years of coding and professional coding experience as an outlier and thus remove such observations.

31 computer skills is quite a lot for some, not so much for others. So let's go with a higher approximation of 35 to remove outliers for this.

193k seems a good critical value for an outlier, but since we do not know the currency of salary, let's not remove the higher salary values. There could be people who had an extremely high salary. This scenario isn't unlikely in our world.

```{r outlier removal}
df_clean = subset(df_clean, subset = df_clean$YearsCode < 40)
df_clean = subset(df_clean, subset = df_clean$YearsCodePro < 40)
df_clean = subset(df_clean, subset = df_clean$ComputerSkills < 35)
```


Lets take a look at the data now:

```{r final data}
df_final <- df_clean
head(df_final)

print(paste("Number of records in final data:", nrow(df_final)))

```


## 4. EDA

Here the `DataExplorer::create_report(df)` function generates a comprehensive exploratory data analysis (EDA) report for a given dataset (`df`). This report includes summary statistics, data visualizations, missing value analysis, and other insights to help users understand and preprocess their data effectively.

```{r}
library(DataExplorer)
#DataExplorer::create_report(df)
```

Here We identify numeric columns in the dataset, created a directory to save histogram plots, and generates histograms for each numeric column. We uses custom colors for the histograms and saves them as individual PNG files in the specified directory for visualizing the data distribution.

```{r }


#names of numeric columns
numeric_cols <- sapply(df, is.numeric)
numeric_cols <- names(df)[numeric_cols]

# Creating a directory to save the plots
output_dir <- "numerical_histograms"
dir.create(output_dir, showWarnings = FALSE)


custom_colors <- c("skyblue", "pink", "orange", "purple", "green")

# Looping through the numerical columns and create histograms
for (col in numeric_cols) {
  color_index <- match(col, numeric_cols) %% length(custom_colors) + 1
  fill_color <- custom_colors[color_index]

  # Creating a histogram
  hist_plot <- ggplot(df, aes(x = .data[[col]]) ) +
    geom_histogram(fill = fill_color, color = "darkblue", bins = 20) +
    labs(title = paste("Histogram of", col),
         x = col,
         y = "Frequency") +
    theme_minimal()

  
  hist_output_file <- file.path(output_dir, paste0("histogram_", col, ".png"))
  ggsave(filename = hist_output_file, plot = hist_plot, width = 6, height = 4)

  print(hist_plot)
}


```

Here we created a map plot of data from the "df_final" dataset, where countries are identified by "Country," and "Age" values are represented by colors on the map.

```{r}
# Creating a map of responses by country
world_map <- map_data("world")
ggplot(data = df_final, aes(map_id = Country)) +
  geom_map(aes(fill = Age), map = world_map) +
  expand_limits(x = world_map$long, y = world_map$lat)

```

Here we created a world map plot using data from the "df_final" dataset. Countries are mapped by "Country," and "MentalHealth" values are visualized using fill colors.

```{r}
ggplot(data = df_final, aes(map_id = Country)) +
  geom_map(aes(fill = MentalHealth), map = world_map) +
  expand_limits(x = world_map$long, y = world_map$lat)
```

Here we created a world map plot with data from the "df_final" dataset. "Country" identifies countries, and "EdLevel" values are represented with fill colors on the map.


```{r}
ggplot(data = df_final, aes(map_id = Country)) +
  geom_map(aes(fill = EdLevel), map = world_map) +
  expand_limits(x = world_map$long, y = world_map$lat)
```

Here we generated a world map plot based on data from the "df_final" dataset. The map represents countries by "Country," and "Employment" values are depicted using fill colors on the map.

```{r}
ggplot(data = df_final, aes(map_id = Country)) +
  geom_map(aes(fill = Employment), map = world_map) +
  expand_limits(x = world_map$long, y = world_map$lat)
```



```{r plot- Ed by Gender}

ggplot(data = subset(df_final, subset = Employed=='hired'), aes(EdLevel, after_stat(count))) + 
  geom_bar(aes(fill = Gender), position = 'dodge', alpha = 0.5) +
  labs(title = "Education Level by gender for employed workers", x="Education Level", y="Count")

```

```{r plot- Ed by Emp}
ggplot(data = df_final, aes(EdLevel)) + 
  geom_bar(aes(fill = Employment), position = 'dodge', alpha = 0.5) +
  labs(title = "Education Level by Employment", x="Education Level", y="Count")

```

```{r plot- MainBranch by Age}
ggplot(data = df_final, aes(MainBranch)) + 
  geom_bar(aes(fill = Age), position = 'dodge', alpha = 0.5) +
  labs(title = "MainBranch by Age", x="MainBranch", y="Count")

```

```{r plot- PrevSal by MentalHealth(1)}
ggplot(data = df_final, aes(x = PreviousSalary, fill = MentalHealth)) +
  geom_density(alpha = 0.5) +
  labs(title = "Density plot of Previous Salary by Mental Health", x="Previous Salary", y= 'Density')

```

```{r plot- PrevSal by MentalHealth(2)}

ggplot(data = df_final, aes(x = MentalHealth, y = PreviousSalary)) +
  geom_jitter(alpha = 0.5, col = 'navy') +
  labs(title = "Previous Salary by Mental Health", x = 'Mental Health', y="Previous Salary")

```

```{r plot- PrevSal by MentalHealth(3)}
plotdata <- df_final %>%
  group_by(MentalHealth) %>%
  summarize(mean_prevsalary = mean(PreviousSalary))

ggplot(data = plotdata, aes(x = MentalHealth, y = mean_prevsalary)) +
  geom_bar(stat = 'identity', alpha = 0.5, aes(fill = MentalHealth)) +
  labs(title = "Mean Previous Salary by Mental Health", x = 'Mental Health', y="Previous Salary")

```

Here we splits the "HaveWorkedWith" column by ";" in the `df_final` dataset. It then groups the resulting data by the skill "HaveWorkedWith," calculates the count of each skill, arranges them in descending order, and stores the top 10 most common skills in the `skills_df` data frame.


```{r skills extraction}

df_final %>%
separate_rows(HaveWorkedWith, sep = ";") %>% 
group_by(HaveWorkedWith) %>%
summarise(Count = n()) %>%
arrange(desc(Count)) -> skills_df
head(skills_df, 10)
```

We see that Javascript, Docker and HTML/CSS are the skills known by majority of the applicants.

```{r plot- Top 10 skills known}

plot <- ggplot(data = head(skills_df, 10), aes(x = reorder(HaveWorkedWith, Count), y = Count)) + 
  geom_bar(stat = 'identity', aes(fill = HaveWorkedWith), alpha = 0.6) + 
  coord_flip() + 
  theme(axis.text.x = element_blank(),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_line(size = 0.1, color = "grey"),
        panel.grid.minor.x = element_line(size = 0.1, color = "grey"),
        plot.background = element_blank()) + 
  geom_text(aes(y = Count, label = Count)) +
  labs(title = "Skills used by number of applicants", 
       x = "Skill", y = "No. of applicants possessing the skill")

anim <- plot + 
    transition_states(HaveWorkedWith, transition_length = 4, wrap = FALSE) + 
  shadow_mark() + 
  enter_grow() +
  enter_fade() + 
  ease_aes('sine-in')
  
animate(anim)
#anim_save("Skills.gif", anim)
```

Now Lets see the skills that make the most money

```{r plot- Highest earning skills}

df_final %>%
separate_rows(HaveWorkedWith, sep = ";") %>% 
group_by(HaveWorkedWith) -> skills_df2

aggregate(skills_df2$PreviousSalary, by = list(skills_df2$HaveWorkedWith), FUN = sum) %>%
arrange(desc(x)) -> skills_df2
colnames(skills_df2) <- c('Skills', 'TotalEarning')


plot <- ggplot(data = head(skills_df2, 10), aes(x = reorder(Skills, TotalEarning), y = TotalEarning)) + 
  geom_bar(stat = 'identity', aes(fill = Skills), alpha = 0.6) + 
  coord_flip() + 
  theme(axis.text.x = element_blank(),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_line(size = 0.1, color = "grey"),
        panel.grid.minor.x = element_line(size = 0.1, color = "grey"),
        plot.background = element_blank()) + 
  geom_text(aes(y = TotalEarning, label = paste(round(TotalEarning/1000000, 2), 'M'))) +
  labs(title = "Top 10 earning skills", 
       x = "Skill", y = "Total earnings")

anim <- plot + 
    transition_states(Skills, transition_length = 4, wrap = FALSE) + 
  shadow_mark() + 
  enter_grow() +
  enter_fade() + 
  ease_aes('sine-in')
  
animate(anim)
#anim_save("SkillsEarnings.gif", anim)
```


Because we have over 65,000 data points, we can use statistical methods that apply to data satisfying normality conditions (because of the central limit theorem).

MAKE SURE TO INCLUDE TEST ASSUMPTIONS

## 5. Hypotheses Testing

We first want to check whether there is a difference in the number of males vs non-males employed at every level of education.
```{r, two sample z test for undergraduate for proportions}
# We first subset into the different education levels, here undergraduate
undergrad <- subset(df_final, df_final$EdLevel == "Undergraduate")



# For the two sample z test, we need our two samples, males and nonmales
undergrad_male <- subset(undergrad, undergrad$Gender == "Man") # Sample 1, males

undergrad_male_employed <- subset(undergrad_male, undergrad_male$Employment == "currently_employed")
# undergrad_male_nonemployed <- subset(undergrad_male, undergrad_male$Employment != "currently_employed")



undergrad_nonmales <- subset(undergrad, undergrad$Gender != "Man") # Sample 2, females and nonbinary

undergrad_nonmales_employed <- (subset(undergrad_nonmales, undergrad_nonmales$Employment == "currently_employed"))
# undergrad_nonmales_nonemployed <- (subset(undergrad_nonmales, undergrad_nonmales$Employment != "currently_employed"))



undergrad_employed_ztest <- prop.test(c(31509, 2319), c(34855,2547))
undergrad_employed_ztest
```
```{r, two sample z test for masters}
# We first subset into the different education levels, here masters
masters <- subset(df_final, df_final$EdLevel == "Master")


# For the two sample z test, we need our two samples, males and nonmales
masters_male <- subset(masters, masters$Gender == "Man") # Sample 1, males

masters_male_employed <- subset(masters_male, masters_male$Employment == "currently_employed")
# undergrad_male_nonemployed <- subset(undergrad_male, undergrad_male$Employment != "currently_employed")


masters_nonmales <- subset(masters, undergrad$Gender != "Man") # Sample 2, females and nonbinary

masters_nonmales_employed <- (subset(masters_nonmales, masters_nonmales$Employment == "currently_employed"))
# undergrad_nonmales_nonemployed <- (subset(undergrad_nonmales, undergrad_nonmales$Employment != "currently_employed"))



masters_employed_ztest <- prop.test(c(15447, 1105), c(17579,2547))
masters_employed_ztest

```


```{r, two sample z test for PhD}
# We first subset into the different education levels, here PhD
phd <- subset(df_final, df_final$EdLevel == "PhD")


# For the two sample z test, we need our two samples, males and nonmales
phd_male <- subset(phd, phd$Gender == "Man") # Sample 1, males

phd_male_employed <- subset(phd_male, phd_male$Employment == "currently_employed")
# undergrad_male_nonemployed <- subset(undergrad_male, undergrad_male$Employment != "currently_employed")


phd_nonmales <- subset(phd, phd$Gender != "Man") # Sample 2, females and nonbinary

phd_nonmales_employed <- (subset(phd_nonmales, phd_nonmales$Employment == "currently_employed"))
# undergrad_nonmales_nonemployed <- (subset(undergrad_nonmales, undergrad_nonmales$Employment != "currently_employed"))



phd_employed_ztest <- prop.test(c(2153, 185), c(2402,206))
phd_employed_ztest
```


```{r, ANOVA test}
anovaRes = aov(ComputerSkills ~ EdLevel, data=df_final)
summary(anovaRes)
```

```{r, Post Hoc Tukey Test}
# Since we have a highly significant p-value based on our ANOVA test above, we want to conduct a Post Hoc analysis of the test using Tukey's method
tukeyRes <- TukeyHSD(anovaRes)
tukeyRes
```

The Undergraduate, Master, and PhD groups had significantly different computer skills when compared to the Other group, with all of them having lower skills (given the negative "diff" values) and p-values less than 0.05.

```{r, Chi square}
# GOF: dep is categorical, independent x variable is two samples
# We first want to create a contingency table to determine whether classification of age is significant in determining whether an individual is a professional developer or not

# We need four categories: <35, NotDev; >35, NotDev; <35 Dev; >35 Dev
notDev_under35 <- subset(df_final, df_final$Age == "<35" & df_final$MainBranch == "NotDev")
notDev_over35 <- subset(df_final, df_final$Age == ">35" & df_final$MainBranch == "NotDev")
dev_under35 <- subset(df_final, df_final$Age == "<35" & df_final$MainBranch == "Dev")
dev_over35 <- subset(df_final, df_final$Age == ">35" & df_final$MainBranch == "Dev")

# Now we conduct a chi square test of independence

chisq_matrix <- matrix(c(22686,44710,2957,3109), nrow = 2, ncol = 2)

chitest = chisq.test(chisq_matrix)
chitest
```

```{r, two sample t-test for means}
# Subset the PreviousSalary for individuals with 'Yes' and 'No' in the MentalHealth column
salary_yes <- df_final$PreviousSalary[df_final$MentalHealth == "Yes"]
salary_no <- df_final$PreviousSalary[df_final$MentalHealth == "No"]

# Checking the mean of both groups just to get an idea
format(mean(salary_yes, na.rm = TRUE), digits=5)
format(mean(salary_no, na.rm = TRUE), digits=5)

# Now we conduct a two-sample t-test on PreviousSalary between the two groups
ttest_2sample_salary_yes_no <- t.test(salary_yes, salary_no)
ttest_2sample_salary_yes_no

```

Individuals who responded "Yes" for mental health issues had a significantly higher previous salary, with a range of $7,993 to $8,936 more than those individuals who responded "No".
